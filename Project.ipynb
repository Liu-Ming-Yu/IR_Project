{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884c1d7f-fa5f-49bf-8c18-87ec9954753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Data Loading, Indexing with Whoosh, and Baseline TF-IDF Retrieval\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from whoosh import index\n",
    "from whoosh.fields import Schema, TEXT, ID, STORED\n",
    "from whoosh.analysis import StemmingAnalyzer\n",
    "from whoosh.qparser import MultifieldParser\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d814b2b-e591-4a16-bbc0-b567d22c7985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Device Setup (for later embedding steps)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "# 2. Load Snippet Dataset\n",
    "def load_snippets(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load code snippet data from a CSV. Expected columns:\n",
    "      - id: unique identifier for the snippet\n",
    "      - language: programming language (e.g., Python, Java)\n",
    "      - snippet: the code text\n",
    "      - description: brief human-readable description\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    required_cols = {'id', 'language', 'snippet', 'description'}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        raise ValueError(f\"CSV must contain columns {required_cols}\")\n",
    "    df = df.dropna(subset=['id', 'snippet'])\n",
    "    df['id'] = df['id'].astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 3. Whoosh Index Creation\n",
    "def create_or_open_index(index_dir: str, schema: Schema) -> index.Index:\n",
    "    \"\"\"\n",
    "    Create a new Whoosh index or open existing one.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(index_dir):\n",
    "        os.makedirs(index_dir)\n",
    "        ix = index.create_in(index_dir, schema)\n",
    "        print(f\"[INFO] Created new index at {index_dir}\")\n",
    "    else:\n",
    "        ix = index.open_dir(index_dir)\n",
    "        print(f\"[INFO] Opened existing index at {index_dir}\")\n",
    "    return ix\n",
    "\n",
    "# Define schema: id, language, snippet text, description\n",
    "snippet_schema = Schema(\n",
    "    id=ID(stored=True, unique=True),\n",
    "    language=TEXT(stored=True),\n",
    "    snippet=TEXT(stored=True, analyzer=StemmingAnalyzer()),\n",
    "    description=TEXT(stored=True)\n",
    ")\n",
    "\n",
    "# 4. Indexing Function\n",
    "def build_index(df: pd.DataFrame, index_dir: str = \"indexdir\"):\n",
    "    \"\"\"\n",
    "    Build Whoosh index from snippets DataFrame.\n",
    "    \"\"\"\n",
    "    ix = create_or_open_index(index_dir, snippet_schema)\n",
    "    writer = ix.writer()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        writer.update_document(\n",
    "            id=row['id'],\n",
    "            language=row['language'],\n",
    "            snippet=row['snippet'],\n",
    "            description=row.get('description', '')\n",
    "        )\n",
    "    writer.commit()\n",
    "    print(f\"[INFO] Indexed {len(df)} code snippets.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. Baseline Retrieval Function\n",
    "def search_snippets(query: str, index_dir: str = \"indexdir\", top_k: int = 10):\n",
    "    \"\"\"\n",
    "    Perform TF-IDF based search over code snippets.\n",
    "    Returns a list of (id, score, language, snippet, description).\n",
    "    \"\"\"\n",
    "    ix = index.open_dir(index_dir)\n",
    "    # Search over `snippet` and `description` fields\n",
    "    parser = MultifieldParser([\"snippet\", \"description\"], schema=ix.schema)\n",
    "    q = parser.parse(query)\n",
    "    with ix.searcher() as searcher:\n",
    "        results = searcher.search(q, limit=top_k)\n",
    "        hits = []\n",
    "        for hit in results:\n",
    "            hits.append({\n",
    "                'id': hit['id'],\n",
    "                'score': hit.score,\n",
    "                'language': hit['language'],\n",
    "                'snippet': hit['snippet'],\n",
    "                'description': hit['description']\n",
    "            })\n",
    "    return hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1f2cab-4eaa-40ec-8b2f-fc4a54984e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ea51370b6e44f38f4dd4c11094bc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da69d87fad5f46d9b20f86e9a4c8bccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee080c51a9343d2bcbeea0fb162e699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79845ab60aba41af82c186a9e5b9def1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a03a159699f4a5d82f05302aaff27eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0da42784e34cc6a497e587af0267b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae04ea4a017463f9535556dc7e6c0fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 2: Embedding-based Re-ranking with CodeBERT on GPU\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# 1. Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "# 2. Load snippets and prepare embeddings\n",
    "EMBEDDING_DIR = \"embeddings\"\n",
    "EMBEDDING_FILE = os.path.join(EMBEDDING_DIR, \"snippet_embeddings.npz\")\n",
    "MODEL_NAME = \"microsoft/codebert-base\"\n",
    "\n",
    "# Initialize CodeBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def build_snippet_embeddings(csv_path: str, rebuild: bool = False) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build or load embeddings for each code snippet.\n",
    "    Returns a dict mapping snippet IDs to embedding vectors.\n",
    "    \"\"\"\n",
    "    os.makedirs(EMBEDDING_DIR, exist_ok=True)\n",
    "    if os.path.exists(EMBEDDING_FILE) and not rebuild:\n",
    "        print(f\"[INFO] Loading existing embeddings from {EMBEDDING_FILE}\")\n",
    "        data = np.load(EMBEDDING_FILE, allow_pickle=True)\n",
    "        ids = data['ids']\n",
    "        embeddings = data['embeddings']\n",
    "        return {id_: emb for id_, emb in zip(ids.tolist(), embeddings)}\n",
    "\n",
    "    print(\"[INFO] Computing new snippet embeddings...\")\n",
    "    df = load_snippets(csv_path)\n",
    "    ids = []\n",
    "    embs = []\n",
    "    batch_size = 16\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch = df.iloc[i:i+batch_size]\n",
    "            texts = (batch['description'] + \" \" + batch['snippet']).tolist()\n",
    "            # Tokenize\n",
    "            enc = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            # Forward\n",
    "            out = model(**enc)\n",
    "            # Use [CLS] token embedding\n",
    "            cls_emb = out.last_hidden_state[:,0,:]\n",
    "            # Normalize\n",
    "            cls_emb = F.normalize(cls_emb, p=2, dim=1)\n",
    "            # Move to CPU and numpy\n",
    "            batch_embs = cls_emb.cpu().numpy()\n",
    "\n",
    "            for id_, emb in zip(batch['id'], batch_embs):\n",
    "                ids.append(id_)\n",
    "                embs.append(emb)\n",
    "\n",
    "    ids = np.array(ids)\n",
    "    embeddings = np.stack(embs)\n",
    "    np.savez_compressed(EMBEDDING_FILE, ids=ids, embeddings=embeddings)\n",
    "    print(f\"[INFO] Saved embeddings: {EMBEDDING_FILE}\")\n",
    "    return {id_: emb for id_, emb in zip(ids.tolist(), embeddings)}\n",
    "\n",
    "\n",
    "# 3. Re-ranking function\n",
    "def rerank_with_embeddings(\n",
    "    query: str,\n",
    "    csv_path: str,\n",
    "    index_dir: str = \"indexdir\",\n",
    "    top_k: int = 10,\n",
    "    alpha: float = 0.5\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Perform initial TF-IDF retrieval, then re-rank using combined score:\n",
    "    combined_score = alpha * normalized_tfidf + (1 - alpha) * cosine_similarity\n",
    "\n",
    "    Returns list of hits with added 'cosine' and 'combined_score'.\n",
    "    \"\"\"\n",
    "    # Ensure embeddings are built\n",
    "    embeddings_map = build_snippet_embeddings(csv_path)\n",
    "\n",
    "    # Initial retrieval\n",
    "    hits = search_snippets(query, index_dir=index_dir, top_k=top_k)\n",
    "    if not hits:\n",
    "        return []\n",
    "\n",
    "    # Extract tfidf scores\n",
    "    tfidf_scores = np.array([h['score'] for h in hits], dtype=np.float32)\n",
    "    # Normalize TF-IDF to [0,1]\n",
    "    tfidf_norm = (tfidf_scores - tfidf_scores.min()) / (tfidf_scores.max() - tfidf_scores.min() + 1e-8)\n",
    "\n",
    "    # Embed query\n",
    "    with torch.no_grad():\n",
    "        enc = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        q_out = model(**enc)\n",
    "        q_emb = F.normalize(q_out.last_hidden_state[:,0,:], p=2, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    # Compute cosine similarity with each snippet embedding\n",
    "    cos_sims = []\n",
    "    for h in hits:\n",
    "        emb = embeddings_map.get(h['id'])\n",
    "        if emb is None:\n",
    "            cos = 0.0\n",
    "        else:\n",
    "            cos = float(np.dot(q_emb, emb))\n",
    "        cos_sims.append(cos)\n",
    "    cos_sims = np.array(cos_sims, dtype=np.float32)\n",
    "    # Normalize cosine to [0,1]\n",
    "    cos_norm = (cos_sims - cos_sims.min()) / (cos_sims.max() - cos_sims.min() + 1e-8)\n",
    "\n",
    "    # Compute combined score\n",
    "    combined = alpha * tfidf_norm + (1 - alpha) * cos_norm\n",
    "\n",
    "    # Attach scores and sort\n",
    "    for i, h in enumerate(hits):\n",
    "        h['cosine'] = float(cos_sims[i])\n",
    "        h['combined_score'] = float(combined[i])\n",
    "\n",
    "    hits_sorted = sorted(hits, key=lambda x: x['combined_score'], reverse=True)\n",
    "    return hits_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3973124-88d3-4fb7-a5e4-0e082f0b8825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Opened existing index at indexdir\n",
      "[INFO] Indexed 100 code snippets.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e14a6126a7424ba5e585c72a257d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Code Snippet Retrieval</h2>'), Text(value='', description='Query:', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "\n",
    "# Paths and constants\n",
    "CSV_PATH = \"snippets.csv\"\n",
    "INDEX_DIR = \"indexdir\"\n",
    "\n",
    "# Ensure index is built\n",
    "df = load_snippets(CSV_PATH)\n",
    "build_index(df, INDEX_DIR)\n",
    "\n",
    "# UI Widgets\n",
    "query_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your code query here',\n",
    "    description='Query:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "topk_slider = widgets.IntSlider(\n",
    "    value=5, min=1, max=20, step=1,\n",
    "    description='Top K:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "alpha_slider = widgets.FloatSlider(\n",
    "    value=0.5, min=0.0, max=1.0, step=0.05,\n",
    "    description='Alpha (TF-IDF vs. Embeddings):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "search_button = widgets.Button(\n",
    "    description='Search',\n",
    "    button_style='primary',\n",
    "    tooltip='Click to run code snippet search',\n",
    "    icon='search'\n",
    ")\n",
    "output = widgets.Output(layout={'border': '1px solid #ddd'})\n",
    "\n",
    "def on_search_click(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        query = query_input.value.strip()\n",
    "        if not query:\n",
    "            display(HTML(\"<p style='color:red;'>Please enter a query.</p>\"))\n",
    "            return\n",
    "        # Retrieve results\n",
    "        results = rerank_with_embeddings(\n",
    "            query=query,\n",
    "            csv_path=CSV_PATH,\n",
    "            index_dir=INDEX_DIR,\n",
    "            top_k=topk_slider.value,\n",
    "            alpha=alpha_slider.value\n",
    "        )\n",
    "        if not results:\n",
    "            display(HTML(\"<p>No results found.</p>\"))\n",
    "            return\n",
    "        \n",
    "        # Build HTML display\n",
    "        html = f\"<h3>Results for '<em>{query}</em>'</h3>\"\n",
    "        for idx, hit in enumerate(results, 1):\n",
    "            # Summarize snippet\n",
    "            summary = \"\"\n",
    "            for line in hit['snippet'].splitlines():\n",
    "                stripped = line.strip()\n",
    "                if stripped.startswith('#') or stripped.startswith('//') or stripped.startswith('def ') or stripped.startswith('function '):\n",
    "                    summary = stripped\n",
    "                    break\n",
    "            if not summary and hit['snippet'].splitlines():\n",
    "                summary = hit['snippet'].splitlines()[0].strip()\n",
    "            \n",
    "            # Highlight keywords\n",
    "            keywords = [t.lower() for t in query.split() if len(t) > 1]\n",
    "            highlighted = \"\"\n",
    "            for line in hit['snippet'].splitlines():\n",
    "                low = line.lower()\n",
    "                if any(k in low for k in keywords):\n",
    "                    highlighted += f\"<mark>{line}</mark>\\n\"\n",
    "                else:\n",
    "                    highlighted += f\"{line}\\n\"\n",
    "            \n",
    "            html += f\"\"\"\n",
    "            <div style=\"border:1px solid #ccc; padding:10px; margin-bottom:10px; border-radius:5px;\">\n",
    "              <strong>{idx}. [ID: {hit['id']}] ({hit['language']})</strong><br>\n",
    "              <small>Score: {hit['combined_score']:.4f} (tfidf), cosine: {hit['cosine']:.4f}</small><br>\n",
    "              <em>Summary:</em> {summary}<br>\n",
    "              <em>Description:</em> {hit.get('description', '')}<br>\n",
    "              <pre style=\"background:#f7f7f7; padding:10px; overflow:auto; white-space:pre-wrap;\">{highlighted}</pre>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        display(HTML(html))\n",
    "\n",
    "search_button.on_click(on_search_click)\n",
    "\n",
    "# Layout and display\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h2>Code Snippet Retrieval</h2>\"),\n",
    "    query_input,\n",
    "    topk_slider,\n",
    "    alpha_slider,\n",
    "    search_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5876c2-46ae-4549-9d92-4b6cb3a4e254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported annotation_candidates.csv: 10 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>snippet_id</th>\n",
       "      <th>language</th>\n",
       "      <th>description</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>merge two sorted arrays in C++</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C++</td>\n",
       "      <td>Merge two sorted arrays</td>\n",
       "      <td>vector&lt;int&gt; mergeSorted(const vector&lt;int&gt;&amp; a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>format date in Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Swift</td>\n",
       "      <td>Format Date object in Swift</td>\n",
       "      <td>let formatter = DateFormatter()\\nformatter.dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>implement binary search in python</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Python</td>\n",
       "      <td>Implement binary search in Python</td>\n",
       "      <td>def binary_search(arr, x):\\n    low, high = 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>create and start a thread in Java</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>Java</td>\n",
       "      <td>Create and start a Java thread</td>\n",
       "      <td>Thread thread = new Thread(() -&gt; {\\n    System...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>template function example C++</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>C++</td>\n",
       "      <td>Template function example in C++</td>\n",
       "      <td>template&lt;typename T&gt;\\nT add(T a, T b) { return...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               query  rank snippet_id language  \\\n",
       "0     merge two sorted arrays in C++     1          2      C++   \n",
       "1               format date in Swift     1          5    Swift   \n",
       "2  implement binary search in python     1          7   Python   \n",
       "3  create and start a thread in Java     1         16     Java   \n",
       "4      template function example C++     1         19      C++   \n",
       "\n",
       "                         description  \\\n",
       "0            Merge two sorted arrays   \n",
       "1        Format Date object in Swift   \n",
       "2  Implement binary search in Python   \n",
       "3     Create and start a Java thread   \n",
       "4   Template function example in C++   \n",
       "\n",
       "                                             snippet  \n",
       "0  vector<int> mergeSorted(const vector<int>& a, ...  \n",
       "1  let formatter = DateFormatter()\\nformatter.dat...  \n",
       "2  def binary_search(arr, x):\\n    low, high = 0,...  \n",
       "3  Thread thread = new Thread(() -> {\\n    System...  \n",
       "4  template<typename T>\\nT add(T a, T b) { return...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annotation export (top-10 TF-IDF)\n",
    "QUERIES = [\n",
    "    # First 20 queries\n",
    "    \"convert list of tuples to dict python\",\n",
    "    \"merge two sorted arrays in C++\",\n",
    "    \"read JSON file in Java\",\n",
    "    \"python regex find all numbers in string\",\n",
    "    \"format date in Swift\",\n",
    "    \"remove duplicates from array in javascript\",\n",
    "    \"implement binary search in python\",\n",
    "    \"center a div in css\",\n",
    "    \"connect to mysql with php pdo\",\n",
    "    \"async await fetch json javascript\",\n",
    "    \"create and start a thread in Java\",\n",
    "    \"template function example C++\",\n",
    "    \"count occurrences in list with Counter python\",\n",
    "    \"exception handling in Ruby\",\n",
    "    \"launch a goroutine in Go\",\n",
    "    \"list comprehension in Haskell\",\n",
    "    \"map anonymous function in Elixir\",\n",
    "    \"define interface in TypeScript\",\n",
    "    \"compress directory using tar bash\",\n",
    "    \"plot sine wave in MATLAB\",\n",
    "    \n",
    "]\n",
    "\n",
    "records = []\n",
    "for q in QUERIES:\n",
    "    hits = search_snippets(q, INDEX_DIR, top_k=10)\n",
    "    for rank, h in enumerate(hits, start=1):\n",
    "        records.append({\n",
    "            \"query\":       q,\n",
    "            \"rank\":        rank,\n",
    "            \"snippet_id\":  h[\"id\"],\n",
    "            \"language\":    h[\"language\"],\n",
    "            \"description\": h[\"description\"],\n",
    "            \"snippet\":     h[\"snippet\"].replace(\"\\n\", \"\\\\n\")\n",
    "        })\n",
    "\n",
    "annotation_df = pd.DataFrame(records)\n",
    "annotation_df.to_csv(\"snippets.csv\", index=False)\n",
    "print(\"Exported annotation_candidates.csv:\", len(annotation_df), \"rows\")\n",
    "annotation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea4331-856e-4c6f-9b8d-ca11fea0fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics (P@5, nDCG@5)\n",
    "\n",
    "\n",
    "ann = pd.read_csv('annotation_labels.csv')\n",
    "res = pd.read_csv('results.csv')\n",
    "ann['rel_bin'] = ann['relevance'].apply(lambda x: 1 if x.lower().startswith('relevant') else 0)\n",
    "\n",
    "def precision_at_k(res_df, ann_df, k):\n",
    "    records = []\n",
    "    for q in res_df['query'].unique():\n",
    "        df_res = res_df[res_df['query']==q].sort_values('rank').head(k)\n",
    "        df_ann = ann_df[ann_df['query']==q]\n",
    "        merged = pd.merge(df_res, df_ann[['snippet_id','rel_bin']], on='snippet_id', how='left').fillna(0)\n",
    "        p = merged['rel_bin'].mean()\n",
    "        records.append({'query': q, f'P@{k}': p})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def dcg(rels):\n",
    "    return sum((2**r - 1) / np.log2(idx + 2) for idx, r in enumerate(rels))\n",
    "\n",
    "def ndcg_at_k(res_df, ann_df, k):\n",
    "    records = []\n",
    "    for q in res_df['query'].unique():\n",
    "        df_res = res_df[res_df['query']==q].sort_values('rank').head(k)\n",
    "        df_ann = ann_df[ann_df['query']==q]\n",
    "        merged = pd.merge(df_res, df_ann[['snippet_id','rel_bin']], on='snippet_id', how='left').fillna(0)\n",
    "        rels = merged['rel_bin'].tolist()\n",
    "        ideal = sorted(rels, reverse=True)\n",
    "        nd = dcg(rels) / dcg(ideal) if dcg(ideal)>0 else 0.0\n",
    "        records.append({'query': q, f'nDCG@{k}': nd})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "p5 = precision_at_k(res, ann, 5)\n",
    "n5 = ndcg_at_k(res, ann, 5)\n",
    "metrics = pd.merge(p5, n5, on='query')\n",
    "import ace_tools as tools; tools.display_dataframe_to_user('P@5 & nDCG@5', metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
